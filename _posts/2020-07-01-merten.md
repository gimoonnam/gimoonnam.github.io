---
title: "Exposure Fusion by Merten et al.(2009)"
date: 2020-7-1 12:32:28 -0400
categories: ImageProcessing
tags:
  - openCV 
  - exposure fusion
  - Merten's algorithm
use_math: true
---

# Introduction  

  This post is written to study Merten's algorithm for image exposure fusion. I will follow the details on algorithm with theory and practice.
 
  This algorithm carris out multiresolution blending by constructing Gaussian and Laplacian image pyramids. The image blending using such pyramids is a powerful method, and yields a high quality image. 

  Besides, the Mertens' algorithm does not require a conversion to an HDR image, which is thus proposed as an effective method for an image fusion, as a counterpart of others involving the conversion. The demonstration of HDR's fusion will be studied soon though.  



### Quality measures

**Contrast ($C$)**

  Application of a Laplacian filter to the grayscale version of images, and take the absolute value of the filtered image. The contrast map captures details on images such as edges and texture. The resultant map is indicated as $C$. 

**Saturation ($S$)**

  The Saturation measures the degree of the exposure. A longer exposed image contains desaturated colors, which will eventually be clipped off. It is desirable to have saturated colors to make vivid images. Here, the saturation is measured as a STD of R, G, and B at each pixel.


**Well-exposedness ($E$)**

  The raw intensities within a channel reveals how well a pixel is exposed, which is used to make sure that the intensities of all pixels are well ranged between 0 and 1, resepctively, under- and over-exposed. The well-exposedness is evaluated by a Gaussian filter with a mean of 0.5, and this filter applies to each channel individually, each of which will be multiplied to yiled the meausre $E$. 



  The weight map with the above three measures are given as a power function

  $$ 
    W_{ij,k} = \left(C_{ij,k}\right)^{\omega_C}\times \left(S_{ij,k}\right)^{\omega_S} \times \left(E_{ij,k}\right)^{\omega_E}                            
  $$

  where $k$ indicates an index of image in given image stack, and $i,j$ are pixel's indices. The relative contributions of each measure to the weight is controlled by the exponents $\omega_{C,S,E}$, varying between 0 and 1.


## Fusion

  Once the weight maps are constructed for each images, the map needs to be normalized to obtain a consistent result as following,

  $$
    \hat{W}_{ij,k} = \frac{W_{ij,k}}{\left[\sum_{k^{\prime}}^{N} W_{ij,k^{\prime}} \right]}
  $$

  The resultant fusion image can then be obtained via a weighted blending of image stack. But it was turned out that the simple fusion produced undesired disturbing seams and halos on resulting images. 

  To get around this problem, the authors employed a multiple resolutions using pyramidal images decomposition. 

  Before blending images, the Laplacian pyramid is generated as a weighted average of Laplacian decompositions for original images and Gaussian pyramid of the weight map. 

  $$
    \mathbf{L}[R]_{ij}^l = \sum_{k=1}^{N}\mathbf{G}[{\hat W}]_{ij,k}^l \mathbf{L}[I]_{ij,k}^l
  $$

  Then the final result is obtained by collapsing the Laplacian pyramid up to the original image size. 

  $$
    R_{ij} = \sum_{k=1}^N \mathbf{L}[R]_{ij} I_{ij,k}
  $$


  
  
  
  
## 

In highly dynamic scenes, 
Pictures often are over- and under-exposed to the light. 

Bracketed exposure sequence -> a single high dynamic range image 
-> remapped into a single low dynamic range image 

This paper proposed to skip the step of computing HDR image, and immediately fuse the multiple exposure into a high-quality, LDR image for display, which is called exposure fusion

This approach relies on simple quality measures like saturation and contrast, which has  been proved to be very effective. 

Pyramidal image decomposition is the essential technique. 


HDR image processing 
Import LDR images generated from normal camera, which is then converted to HDR 
Camera-specific response function, used to linearize the intensities of pixels. 
To display the acquired HDR images on normal display device, the HDR needs to be compressed by tone mapping. 
Bilateral filtering: widely used technique to compress DR  

Other methods
Pyramidal image decomposition [15]
Rescaling HDR pixel values by multi-scaled contrast 

This paper’s approach: weighted blending 
fuse high quality images from bracketed exposures
Employed pyramid decomposition for weighted blending
The goal is to obtain desired image by keeping the best parts


Quality Measures 

Contrast: apply a Laplacian filter to the grayscale version of each image, and take the absolute value of the filter response, which will yield a simple indicator C for contrast. by which edges and texture will have highly weights.
Saturation S: longer exposed image -> color desaturated and eventually clipped  S is computed as a STD within R,G,and B channel at each pixel 
Well-exposedness (E): pixel’s intensity is near 0 for underexposed and 1 for overexposed. By applying Gaussian curve, the intensity is kept to be about 0.5




Fusion 

Weight map also needs to be smoothed by Gaussian filter to avoid sharp transitions 
Cross-bilateral filter is a better alternative 

Laplacian pyramid decomposition 
multiresolution blending based on image pyramids 
Gradient-based blending shown to be effective 


What is color saturation? Color saturation refers to the intensity of color in an image. As the saturation increases, the colors appear to be more pure, while as the saturation decreases, the colors appear to be more washed-out or pale. 

Image compression 
(lossy and lossless image compression)

Pyramid decomposition : multi-scale signal representation developed by computer vision, image processing, and signal processing communities, in which a signal or an image  is subject to repeated smoothing and subsampling. 
Gaussian pyramid 
Laplacian pyramid 
Steerable pyramid 
